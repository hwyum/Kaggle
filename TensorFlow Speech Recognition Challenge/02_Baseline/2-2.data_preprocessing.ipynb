{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pytorch에서 제공하는 torch.utils.data의 Dataset 클래스를 통해 데이터셋 만듬.\n",
    "<br> 이때 아래 두 가지 함수 필수 구현 필요\n",
    "    * __len__(): 함수를 통해 데이터의 크기 반환\n",
    "    * __getitem__(): i번째 데이터(dataset[i])를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "from glob import glob\n",
    "import random\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "# 음성 파일의 sample rate은 1초 = 16000으로 지정한다\n",
    "SR = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## np.pad test\n",
    "x = np.asarray([1,2,3,4,5,6])\n",
    "np.pad(x,(5,3),'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980062"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 소음 데이터 확인\n",
    "x = \"../data/train/audio/_background_noise_/exercise_bike.wav\"\n",
    "data = librosa.load(x, sr=SR)\n",
    "ipd.Audio(data[0], rate=data[1])\n",
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경진대회 전용 SpeechDataset 클래스를 정의한다\n",
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, mode, label_to_int, wav_list, label_list=None):\n",
    "        self.mode = mode\n",
    "        self.label_to_int = label_to_int\n",
    "        self.wav_list = wav_list\n",
    "        self.label_list = label_list\n",
    "        self.sr = SR\n",
    "        self.n_silence = int(len(wav_list) * 0.1) #  silence학습을 위해 10%의 무음 데이터 생성\n",
    "\n",
    "        # 배경 소음 데이터를 미리 읽어온다\n",
    "        self.background_noises = [librosa.load(x, sr=self.sr)[0] for x in glob(\"../data/train/audio/_background_noise_/*.wav\")]\n",
    "\n",
    "    def get_one_word_wav(self, idx):\n",
    "        # idx 번째 음성 파일을 1초만큼 읽어온다\n",
    "        wav = librosa.load(self.wav_list[idx], sr=self.sr)[0]\n",
    "        if len(wav) < self.sr: ## 음성 길이가 sample rate보다 짧은 경우, 부족한 길이만큼 padding \n",
    "            wav = np.pad(wav, (0, self.sr - len(wav)), 'constant')\n",
    "        return wav[:self.sr]\n",
    "\n",
    "    def get_one_noise(self):\n",
    "        # 배경 소음 데이터 중 랜덤하게 1초를 읽어온다\n",
    "        selected_noise = self.background_noises[random.randint(0, len(self.background_noises) - 1)]\n",
    "        start_idx = random.randint(0, len(selected_noise) - 1 - self.sr)\n",
    "        return selected_noise[start_idx:(start_idx + self.sr)]\n",
    "\n",
    "    def get_mix_noises(self, num_noise=1, max_ratio=0.1): ##?????????\n",
    "        # num_noise 만큼의 배경 소음을 합성한다\n",
    "        result = np.zeros(self.sr)\n",
    "        for _ in range(num_noise):\n",
    "            result += random.random() * max_ratio * self.get_one_noise()\n",
    "        return result / num_noise if num_noise > 0 else result\n",
    "\n",
    "    def get_silent_wav(self, num_noise=1, max_ratio=0.5):\n",
    "        # 배경 소음 데이터를 silence로 가정하고 불러온다\n",
    "        return self.get_mix_noises(num_noise=num_noise, max_ratio=max_ratio)\n",
    "\n",
    "    def __len__(self):\n",
    "        # 교차검증 모드일 경우에는 ‘silence’를 추가한 만큼이 데이터 크기이고, Test 모드일 경우에는 제공된 테스트 데이터가 전부이다\n",
    "        if self.mode == 'test':\n",
    "            return len(self.wav_list)\n",
    "        else:\n",
    "            return len(self.wav_list) + self.n_silence\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # idx번째 음성 데이터 하나를 반환한다\n",
    "        if idx < len(self.wav_list):\n",
    "            # 전처리는 mel spectrogram으로 지정한다\n",
    "            # (옵션) 여기서 Data Augmentation을 수행할 수 있다.\n",
    "            wav_numpy = preprocess_mel(self.get_one_word_wav(idx))\n",
    "            wav_tensor = torch.from_numpy(wav_numpy).float()\n",
    "            wav_tensor = wav_tensor.unsqueeze(0)\n",
    "\n",
    "            # 음성 스펙트로그램(spec), 파일 경로(id)와 정답값(label)을 반환한다\n",
    "            if self.mode == 'test':\n",
    "                return {'spec': wav_tensor, 'id': self.wav_list[idx]}\n",
    "            else:\n",
    "                label = self.label_to_int.get(self.label_list[idx], len(self.label_to_int))\n",
    "                return {'spec': wav_tensor, 'id': self.wav_list[idx], 'label': label}\n",
    "        else:\n",
    "            # 배경 소음을 반환한다\n",
    "            wav_numpy = preprocess_mel(self.get_silent_wav(\n",
    "                num_noise=random.choice([0, 1, 2, 3]),\n",
    "                max_ratio=random.choice([x / 10. for x in range(20)])))\n",
    "            wav_tensor = torch.from_numpy(wav_numpy).float()\n",
    "            wav_tensor = wav_tensor.unsqueeze(0)\n",
    "            return {'spec': wav_tensor, 'id': 'silence', 'label': len(self.label_to_int) + 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel spectrogram 전처리 함수이다\n",
    "def preprocess_mel(data, n_mels=40):\n",
    "    spectrogram = librosa.feature.melspectrogram(data, sr=SR, n_mels=n_mels, hop_length=160, \\\n",
    "                                                 n_fft=480, fmin=20, fmax=4000)\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_word_wav(wav_list, idx):\n",
    "    # idx 번째 음성 파일을 1초만큼 읽어온다\n",
    "    wav = librosa.load(wav_list[idx], sr=SR)[0]\n",
    "    if len(wav) < SR: ## 음성 길이가 sample rate보다 짧은 경우, 부족한 길이만큼 padding \n",
    "        wav = np.pad(wav, (0, SR - len(wav)), 'constant')\n",
    "    return wav[:SR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./input/trn.txt')\n",
    "wav_list = []\n",
    "\n",
    "for line in f.readlines():\n",
    "#     print(line)\n",
    "    wav = line.split(',')[2].split('\\n')[0]\n",
    "    wav_list.append(wav)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wav = get_one_word_wav(wav_list, 0)\n",
    "test_wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 101)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_numpy = preprocess_mel(test_wav)\n",
    "wav_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_noises = [librosa.load(x, sr=SR)[0] for x in glob(\"../data/train/audio/_background_noise_/*.wav\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_one_noise():\n",
    "        # 배경 소음 데이터 중 랜덤하게 1초를 읽어온다\n",
    "        selected_noise = background_noises[random.randint(0, len(background_noises) - 1)]\n",
    "        start_idx = random.randint(0, len(selected_noise) - 1 - SR)\n",
    "        return selected_noise[start_idx:(start_idx + SR)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41488647,  0.22940063, -0.05651855, ...,  0.47747803,\n",
       "        0.15432739,  0.2833252 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_one_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
