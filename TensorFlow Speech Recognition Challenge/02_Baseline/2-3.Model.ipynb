{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import MaxPool2d\n",
    "import glob\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 모델을 구현한다\n",
    "class ResModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResModel, self).__init__()\n",
    "        # 이번 경진대회에 사용되는 label 개수는 12이다\n",
    "        n_labels = 12\n",
    "        n_maps = 128 ## 채널수(필터갯수)\n",
    "        # 총 9계층 모델을 쌓는다\n",
    "        self.n_layers = n_layers = 9\n",
    "        # 첫 계층에 사용하는 convolutional 모듈을 정의한다\n",
    "        self.conv0 = torch.nn.Conv2d(1, n_maps, (3, 3), padding=(1, 1), bias=False)\n",
    "        # MaxPooling 모듈을 정의한다\n",
    "        self.pool = MaxPool2d(2, return_indices=True)\n",
    "        # 2계층 이후에 사용하는 convolutional 모듈을 정의한다\n",
    "        self.convs = torch.nn.ModuleList([torch.nn.Conv2d(n_maps, n_maps, (3, 3), padding=1, dilation=1, bias=False) for _ in range(n_layers)])\n",
    "        # BatchNormalization 모듈과 conv 모듈을 조합한다\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            self.add_module(\"bn{}\".format(i + 1), torch.nn.BatchNorm2d(n_maps, affine=False))\n",
    "            self.add_module(\"conv{}\".format(i + 1), conv)\n",
    "        # 최종 계층에는 선형 모듈을 추가한다\n",
    "        self.output = torch.nn.Linear(n_maps, n_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_layers + 1):\n",
    "            y = F.relu(getattr(self, \"conv{}\".format(i))(x))\n",
    "            if i == 0:\n",
    "                old_x = y\n",
    "            # 이전 layer의 결과값(old_x)와 이번 layer 결과값(y)을 더하는 것이 residual 모듈이다 \n",
    "            if i > 0 and i % 2 == 0:\n",
    "                x = y + old_x\n",
    "                old_x = x\n",
    "            else:\n",
    "                x = y\n",
    "            # BatchNormalization을 통해 파라미터 값을 정규화한다\n",
    "            if i > 0:\n",
    "                x = getattr(self, \"bn{}\".format(i))(x)\n",
    "            # pooling을 사용할지 True/False로 지정한다\n",
    "            pooling = False\n",
    "            if pooling:\n",
    "                x_pool, pool_indices = self.pool(x)\n",
    "                x = self.unpool(x_pool, pool_indices, output_size=x.size())\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        x = torch.mean(x, 2)\n",
    "        # 최종 선형 계층을 통과한 결과값을 반환한다\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model trainer\n",
    "\"\"\"\n",
    "from torch.autograd import Variable\n",
    "from data import SpeechDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from time import time\n",
    "from torch.nn import Softmax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from random import choice\n",
    "from resnet import ResModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_directory(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def get_time(now, start):\n",
    "    time_in_min = int((now - start) / 60)\n",
    "    return time_in_min\n",
    "\n",
    "# 학습을 위한 기본 설정값을 지정한다\n",
    "BATCH_SIZE = 32  # 데이터 묶음에 해당하는 batch_size는 GPU 메모리에 알맞게 지정한다\n",
    "mGPU = False  # multi-GPU를 사용할 경우에는 True로 지정한다\n",
    "epochs = 20  # 모델이 훈련 데이터를 학습하는 횟수를 지정한다\n",
    "mode = 'cv' # 교차 검증 모드(cv) or 테스트 모드(test)\n",
    "model_name = 'model/model_resnet.pth'  # 모델 결과물을 저장할 때 모델 이름을 지정한다\n",
    "\n",
    "# ResNet 모델을 활성화한다\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "model = ResModel\n",
    "speechmodel = torch.nn.DataParallel(model()) if mGPU else model()\n",
    "# speechmodel = speechmodel.cuda()\n",
    "\n",
    "# SpeechDataset을 활성화한다\n",
    "labels = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "label_to_int = dict(zip(labels, range(len(labels))))\n",
    "int_to_label = dict(zip(range(len(labels)), labels))\n",
    "int_to_label.update({len(labels): 'unknown', len(labels) + 1: 'silence'})\n",
    "\n",
    "# 모드에 따라 학습 및 검증에 사용할 파일을 선택한다\n",
    "trn = 'input/trn.txt' if mode == 'cv' else 'input/trn_all.txt'\n",
    "tst = 'input/val.txt' if mode == 'cv' else 'input/tst.txt'\n",
    "\n",
    "\n",
    "trn = [line.strip() for line in open(trn, 'r').readlines()]\n",
    "wav_list = [line.split(',')[-1] for line in trn]\n",
    "label_list = [line.split(',')[0] for line in trn]\n",
    "# 학습용 SpeechDataset을 불러온다\n",
    "traindataset = SpeechDataset(mode='train', label_to_int=label_to_int, wav_list=wav_list, label_list=label_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindataset.background_noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/980 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (0,0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8003e205a89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 학습을 수행한다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# batch_size 만큼의 음성 데이터(spec)와 정답값(label)을 받아온다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_time\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_time\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             self.bar_format, self.postfix, self.unit_divisor)\n\u001b[0;32m--> 941\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_comparable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Data Science_Reference/Kaggle/TensorFlow Speech Recognition Challenge/02_Baseline/data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     73\u001b[0m             wav_numpy = preprocess_mel(self.get_silent_wav(\n\u001b[1;32m     74\u001b[0m                 \u001b[0mnum_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 max_ratio=random.choice([x / 10. for x in range(20)])))\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mwav_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mwav_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Data Science_Reference/Kaggle/TensorFlow Speech Recognition Challenge/02_Baseline/data.py\u001b[0m in \u001b[0;36mget_silent_wav\u001b[0;34m(self, num_noise, max_ratio)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_silent_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# 배경 소음 데이터를 silence로 가정하고 불러온다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mix_noises\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Data Science_Reference/Kaggle/TensorFlow Speech Recognition Challenge/02_Baseline/data.py\u001b[0m in \u001b[0;36mget_mix_noises\u001b[0;34m(self, num_noise, max_ratio)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_one_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_noise\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_noise\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Data Science_Reference/Kaggle/TensorFlow Speech Recognition Challenge/02_Baseline/data.py\u001b[0m in \u001b[0;36mget_one_noise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_one_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# 배경 소음 데이터 중 랜덤하게 1초를 읽어온다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mselected_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackground_noises\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackground_noises\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_noise\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mselected_noise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d,%d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# Non-unit step argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (0,0, 0)"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "for e in range(epochs):\n",
    "    print(\"training epoch \", e)\n",
    "    # learning_rate를 epoch마다 다르게 지정한다\n",
    "    learning_rate = 0.01 if e < 10 else 0.001\n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, speechmodel.parameters()), lr=learning_rate, momentum=0.9, weight_decay=0.00001)\n",
    "    # 모델을 학습하기 위하여 .train() 함수를 실행한다\n",
    "    speechmodel.train()\n",
    "\n",
    "    total_correct = 0\n",
    "    num_labels = 0\n",
    "    trainloader = DataLoader(traindataset, BATCH_SIZE, shuffle=True)\n",
    "    # 학습을 수행한다\n",
    "    for batch_idx, batch_data in enumerate(tqdm(trainloader)):\n",
    "        # batch_size 만큼의 음성 데이터(spec)와 정답값(label)을 받아온다\n",
    "        spec = batch_data['spec']\n",
    "        label = batch_data['label']\n",
    "#         spec, label = Variable(spec.cuda()), Variable(label.cuda())\n",
    "        # 현재 모델의 예측값(y_pred)을 계산한다\n",
    "        y_pred = speechmodel(spec)\n",
    "        _, pred_labels = torch.max(y_pred.data, 1)\n",
    "        correct = (pred_labels == label.data).sum()\n",
    "        # 정답과 예측값간의 차이(loss)를 계산한다 \n",
    "        loss = loss_fn(y_pred, label)\n",
    "\n",
    "        total_correct += correct\n",
    "        num_labels += len(label)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        # loss를 기반으로 back-propagation을 수행한다\n",
    "        loss.backward()\n",
    "        # 모델 파라미터를 업데이트한다. (실질적 학습)\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 훈련 데이터에서의 정확률을 기록한다\n",
    "    print(\"training accuracy:\", 100. * total_correct / num_labels, get_time(time(), start_time))\n",
    "\n",
    "    # 교차 검증 모드의 경우, 검증 데이터에 대한 정확률을 기록한다\n",
    "    if mode == 'cv':\n",
    "        # 현재 학습 중인 모델을 임시로 저장한다\n",
    "        torch.save(speechmodel.state_dict(), '{}_cv'.format(model_name))\n",
    "        \n",
    "        # 검증 데이터를 불러온다\n",
    "        softmax = Softmax()\n",
    "        tst_list = [line.strip() for line in open(tst, 'r').readlines()]\n",
    "        wav_list = [line.split(',')[-1] for line in tst_list]\n",
    "        label_list = [line.split(',')[0] for line in tst_list]\n",
    "        cvdataset = SpeechDataset(mode='test', label_to_int=label_to_int, wav_list=wav_list)\n",
    "        cvloader = DataLoader(cvdataset, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # 모델을 불러와 .eval() 함수로 검증 준비를 한다\n",
    "        speechmodel = torch.nn.DataParallel(model()) if mGPU else model()\n",
    "        speechmodel.load_state_dict(torch.load('{}_cv'.format(model_name)))\n",
    "#         speechmodel = speechmodel.cuda()\n",
    "        speechmodel.eval()\n",
    "\n",
    "        # 검증 데이터를 batch_size만큼씩 받아오며 예측값을 저장한다\n",
    "        fnames, preds = [], []\n",
    "        for batch_idx, batch_data in enumerate(tqdm(cvloader)):\n",
    "            spec = Variable(batch_data['spec'].cuda())\n",
    "            fname = batch_data['id']\n",
    "            y_pred = softmax(speechmodel(spec))\n",
    "            preds.append(y_pred.data.cpu().numpy())\n",
    "            fnames += fname\n",
    "\n",
    "        preds = np.vstack(preds)\n",
    "        preds = [int_to_label[x] for x in np.argmax(preds, 1)]\n",
    "        fnames = [fname.split('/')[-2] for fname in fnames]\n",
    "        num_correct = 0\n",
    "        for true, pred in zip(fnames, preds):\n",
    "            if true == pred:\n",
    "                num_correct += 1\n",
    "\n",
    "        # 검증 데이터의 정확률을 기록한다\n",
    "        print(\"cv accuracy:\", 100. * num_correct / len(preds), get_time(time(), start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습이 완료된 모델을 저장한다\n",
    "create_directory(\"model\")\n",
    "torch.save(speechmodel.state_dict(), model_name)\n",
    "\n",
    "# 테스트 데이터에 대한 예측값을 파일에 저장한다\n",
    "print(\"doing prediction...\")\n",
    "softmax = Softmax()\n",
    "\n",
    "# 테스트 데이터를 불러온다\n",
    "tst = [line.strip() for line in open(tst, 'r').readlines()]\n",
    "wav_list = [line.split(',')[-1] for line in tst]\n",
    "testdataset = SpeechDataset(mode='test', label_to_int=label_to_int, wav_list=wav_list)\n",
    "testloader = DataLoader(testdataset, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 모델을 불러온다\n",
    "speechmodel = torch.nn.DataParallel(model()) if mGPU else model()\n",
    "speechmodel.load_state_dict(torch.load(model_name))\n",
    "speechmodel = speechmodel.cuda()\n",
    "speechmodel.eval()\n",
    "    \n",
    "test_fnames, test_labels = [], []\n",
    "pred_scores = []\n",
    "\n",
    "# 테스트 데이터에 대한 예측값을 계산한다\n",
    "for batch_idx, batch_data in enumerate(tqdm(testloader)):\n",
    "    spec = Variable(batch_data['spec'].cuda())\n",
    "    fname = batch_data['id']\n",
    "    y_pred = softmax(speechmodel(spec))\n",
    "    pred_scores.append(y_pred.data.cpu().numpy())\n",
    "    test_fnames += fname\n",
    "\n",
    "# 가장 높은 확률값을 가진 예측값을 label 형태로 저장한다\n",
    "final_pred = np.vstack(pred_scores)\n",
    "final_labels = [int_to_label[x] for x in np.argmax(final_pred, 1)]\n",
    "test_fnames = [x.split(\"/\")[-1] for x in test_fnames]\n",
    "\n",
    "# 테스트 파일 명과 예측값을 sub 폴더 아래 저장한다. 캐글에 직접 업로드 할 수 있는 파일 포맷이다.\n",
    "create_directory(\"sub\")\n",
    "pd.DataFrame({'fname': test_fnames, 'label': final_labels}).to_csv(\"sub/{}.csv\".format(model_name.split('/')[-1]), index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-acca3bfebeee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbackground_noises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/train/audio/_background_noise_/*.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "SR = 16000\n",
    "background_noises = [librosa.load(x, sr=SR)[0] for x in glob(\"../data/train/audio/_background_noise_/*.wav\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
